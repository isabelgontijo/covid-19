{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51a28240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T18:21:50.174024Z",
     "start_time": "2022-01-13T18:21:50.160802Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50170e51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T18:21:50.182608Z",
     "start_time": "2022-01-13T18:21:50.178342Z"
    }
   },
   "outputs": [],
   "source": [
    "id_path = '/Users/IsabelGontijo/git/covid-19/refined/data/02_id_creation/'\n",
    "std_path = '/Users/IsabelGontijo/git/covid-19/refined/data/03_standardization/'\n",
    "dic_file = '/Users/IsabelGontijo/git/covid-19/refined/metadata/03_standardization/dic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f547994",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T18:21:55.548978Z",
     "start_time": "2022-01-13T18:21:50.188022Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load dictionary\n",
    "dic = spark.read.csv(dic_file, multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a2b1bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T18:21:55.968867Z",
     "start_time": "2022-01-13T18:21:55.552318Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load id_cidacs base\n",
    "df = spark.read.csv(id_path, header=True, multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecba391f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T18:21:56.627188Z",
     "start_time": "2022-01-13T18:21:55.972685Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df = df.withColumnRenamed(col, col.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1713f2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T18:21:56.651815Z",
     "start_time": "2022-01-13T18:21:56.630476Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "def standardizeDate(s):\n",
    "    if s:\n",
    "        # condic datas come with hours after the actual date\n",
    "        # takes the date\n",
    "        s = s.split()[0]\n",
    "        \n",
    "        separators = ['-', '/']\n",
    "        for sep in separators:\n",
    "            s = s.replace(sep, '')\n",
    "        try:\n",
    "            value = int(s)\n",
    "        except ValueError:\n",
    "            return None\n",
    "        if len(s) == 7:\n",
    "            s = '0' + s\n",
    "        if len(s) != 8:\n",
    "            return None\n",
    "        # check true date\n",
    "        try:\n",
    "            year = int(s[:4])\n",
    "            month = int(s[4:6])\n",
    "            day = int(s[6:])\n",
    "            data = date(year, month, day)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                year = int(s[4:])\n",
    "                month = int(s[2:4])\n",
    "                day = int(s[0:2])\n",
    "                data = date(year, month, day)\n",
    "            except ValueError:\n",
    "                return None\n",
    "        # spark bug (does not allow years near 0001)\n",
    "        if year < 1000:\n",
    "            return None\n",
    "        # check ordinal\n",
    "        if data.toordinal() < 1:\n",
    "            return None\n",
    "        # works\n",
    "        return data\n",
    "    else:\n",
    "        return None\n",
    "# Register UDF\n",
    "udf_standardizeDate = F.udf(standardizeDate, DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b613483b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T18:21:56.661695Z",
     "start_time": "2022-01-13T18:21:56.657280Z"
    }
   },
   "outputs": [],
   "source": [
    "def standardizeInteger(s):\n",
    "    if s:\n",
    "        try:\n",
    "            int(s)\n",
    "        except:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "#Register UDF\n",
    "udf_standardizeInteger = F.udf(standardizeInteger, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7df178f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T18:21:56.675565Z",
     "start_time": "2022-01-13T18:21:56.669645Z"
    }
   },
   "outputs": [],
   "source": [
    "def standardizeDouble(s):\n",
    "    if s:\n",
    "        try:\n",
    "            s = float(s)\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "#Register UDF\n",
    "udf_standardizeDouble = F.udf(standardizeDouble, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5975002",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T18:21:56.705521Z",
     "start_time": "2022-01-13T18:21:56.691690Z"
    }
   },
   "outputs": [],
   "source": [
    "#Standardize bytes. The function takes an field containing the \n",
    "#transformation rules, which are present in the base dictionary\n",
    "\n",
    "def standardizeByte(s, t):\n",
    "    if s:\n",
    "        import json\n",
    "        t = t.replace(\"'\", '\"')\n",
    "        dicT = json.loads(t)\n",
    "        if 'integer_key' in dicT and dicT['integer_key'] == '1':\n",
    "            try:\n",
    "                s = int(s)\n",
    "            except:\n",
    "                return 99\n",
    "        if str(s) in dicT.keys():\n",
    "            return int(dicT[str(s)])\n",
    "        else:\n",
    "            return 99\n",
    "    else:\n",
    "        return 0\n",
    "udf_standardizeByte = F.udf(standardizeByte, ByteType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b7d65f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T18:21:56.723211Z",
     "start_time": "2022-01-13T18:21:56.715502Z"
    }
   },
   "outputs": [],
   "source": [
    "def standardizeLong(s):\n",
    "    if s:\n",
    "        try:\n",
    "            s = int(s)\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "#Register UDF\n",
    "udf_standardizeLong = F.udf(standardizeLong, LongType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d87470a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T18:21:56.744935Z",
     "start_time": "2022-01-13T18:21:56.731960Z"
    }
   },
   "outputs": [],
   "source": [
    "#For each dictionary entry, associate column name with its corresponding standardize function.\n",
    "def createdStandardizedFunctions(dic):\n",
    "    standardizedFunctions = {}\n",
    "    #Get base dictionary to list\n",
    "    listDic = dic.collect()\n",
    "    for item in listDic:\n",
    "        cName = item._c0\n",
    "        cType = item._c1\n",
    "        cTransf = item._c2\n",
    "        \n",
    "        if cType == \"String\":\n",
    "            standardizedFunctions[cName] = None\n",
    "        elif cTransf:\n",
    "            standardizedFunctions[cName] = \"df.withColumn('\" + cName + \"', udf_standardize\" + cType + \"(df['\" + cName + \"'], F.lit(\\\"\" + cTransf.replace(\"\\n\",\"\") + \"\\\")))\"\n",
    "        else:\n",
    "            standardizedFunctions[cName] = \"df.withColumn('\" + cName + \"', udf_standardize\" + cType + \"(df['\" + cName + \"']))\"\n",
    "\n",
    "    return standardizedFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7aaac16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T18:21:58.389581Z",
     "start_time": "2022-01-13T18:21:56.756427Z"
    }
   },
   "outputs": [],
   "source": [
    "standardizedDic = createdStandardizedFunctions(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd0226a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T18:24:01.969153Z",
     "start_time": "2022-01-13T18:21:58.391867Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "        #String columns should have null standardize functions\n",
    "        if standardizedDic[column]:\n",
    "            #Apply standardize function to database\n",
    "            df = eval(standardizedDic[column])\n",
    "    #Write standardized files\n",
    "df.write.parquet(std_path, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afa9a1aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T18:24:02.929441Z",
     "start_time": "2022-01-13T18:24:01.971633Z"
    }
   },
   "outputs": [],
   "source": [
    "if sc: sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21b1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
